{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from datasets import Dataset\n",
    "from underthesea import word_tokenize\n",
    "from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'data.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[['content', 'label']]\n",
    "\n",
    "labels_map = {\n",
    "    \"POS\": 0,\n",
    "    \"NEU\": 1,\n",
    "    \"NEG\": 2\n",
    "}\n",
    "\n",
    "df['label'] = df['label'].map(labels_map)\n",
    "df = df.dropna(subset=['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    for emoji in UNICODE_EMOJI.values():\n",
    "        text = text.replace(emoji, \"\")\n",
    "    for emoticon in EMOTICONS_EMO.values():\n",
    "        text = text.replace(emoticon, \"\")\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', ' <num> ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r\"[!@#$\\[\\]()']\", \"\", text)\n",
    "\n",
    "    with open('vietnamese-stopwords.txt', \"r\", encoding=\"utf-8\") as f:\n",
    "        stopwords = set(f.read().split(\"\\n\"))\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    text = \" \".join(word for word in words if word not in stopwords)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>Vẫn tặng bạn 5* vì nhiệt tình</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16959</th>\n",
       "      <td>Dù có 5k nhưg mất uy tín</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>Hàng đẹp dã man chị trang ạ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20374</th>\n",
       "      <td>Và con nào ăn thì con đấy chết</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>Chất lượng tốt có nhiều quà tặng kèm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9676</th>\n",
       "      <td>Có giảm nhưng uống vào người rất mệt và buồn nôn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Đóng gói sản phẩm rất đẹp và chắc chắn Shop ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>Đây chỉ là góp ý và không nỡ để shop bị rate t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>Chất vải và kiểu áo đều ok, dễ mặc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9695</th>\n",
       "      <td>Chất vải quá tồi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "2604                       Vẫn tặng bạn 5* vì nhiệt tình      0\n",
       "16959                           Dù có 5k nhưg mất uy tín      1\n",
       "19018                        Hàng đẹp dã man chị trang ạ      0\n",
       "20374                     Và con nào ăn thì con đấy chết      2\n",
       "11124               Chất lượng tốt có nhiều quà tặng kèm      0\n",
       "...                                                  ...    ...\n",
       "9676    Có giảm nhưng uống vào người rất mệt và buồn nôn      1\n",
       "622    Đóng gói sản phẩm rất đẹp và chắc chắn Shop ph...      0\n",
       "6249   Đây chỉ là góp ý và không nỡ để shop bị rate t...      1\n",
       "926                   Chất vải và kiểu áo đều ok, dễ mặc      0\n",
       "9695                                    Chất vải quá tồi      2\n",
       "\n",
       "[15000 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.sample(n=15000, random_state=42)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['content'] = df_test['content'].apply(remove_emoji)  \n",
    "df_test['content'] = df_test['content'].apply(clean_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df_test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "checkpoint = 'distilbert-base-multilingual-cased'\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"content\"], truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525333419e944f878d66665c43f70a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded25f6006da4ca4bc2620160707a066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "val_dataset = val_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loại bỏ các cột không cần thiết\n",
    "train_dataset = train_dataset.remove_columns([\"content\", \"__index_level_0__\", \"attention_mask\"])\n",
    "val_dataset = val_dataset.remove_columns([\"content\", \"__index_level_0__\", \"attention_mask\"])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids'],\n",
       "    num_rows: 12000\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, collate_fn=data_collator)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=10, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch.keys())\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, max_length):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Take the last output of the LSTM\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 119547\n",
      "Embedding dimension: 128\n",
      "Hidden size: 64\n",
      "Output size: 3\n",
      "Max length: 128\n",
      "Number of epochs: 10\n"
     ]
    }
   ],
   "source": [
    "# HYPER PARAMS\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 128\n",
    "hidden_size = 64\n",
    "output_size = 3\n",
    "max_length = 128\n",
    "num_epochs = 10\n",
    "device = device\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Hidden size: {hidden_size}\")\n",
    "print(f\"Output size: {output_size}\")\n",
    "print(f\"Max length: {max_length}\")\n",
    "print(f\"Number of epochs: {num_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=10, best_model_path=None):\n",
    "    best_val_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch['input_ids'], batch['labels']\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "        \n",
    "        train_loss = running_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        val_loss, val_accuracy, val_f1 = evaluate(model, val_loader, criterion, device)  # Now unpack 3 values\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_accuracy > best_val_accuracy and best_model_path:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f} Train Accuracy: {train_accuracy:.4f} \"\n",
    "              f\"Val Loss: {val_loss:.4f} Val Accuracy: {val_accuracy:.4f} Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    print(\"Training complete\")\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    running_val_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs, labels = batch['input_ids'], batch['labels']\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    val_loss = running_val_loss / len(loader)\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')  # Calculate F1 score\n",
    "    \n",
    "    return val_loss, val_accuracy, f1  # Return 3 values now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Train Loss: 0.9109 Train Accuracy: 0.6410 Val Loss: 0.8998 Val Accuracy: 0.6367 Val F1: 0.4953\n",
      "Epoch [2/20] Train Loss: 0.9047 Train Accuracy: 0.6418 Val Loss: 0.8989 Val Accuracy: 0.6367 Val F1: 0.4953\n",
      "Epoch [3/20] Train Loss: 0.9041 Train Accuracy: 0.6419 Val Loss: 0.9010 Val Accuracy: 0.6367 Val F1: 0.4953\n",
      "Epoch [4/20] Train Loss: 0.8498 Train Accuracy: 0.6509 Val Loss: 0.6958 Val Accuracy: 0.7333 Val F1: 0.6804\n",
      "Epoch [5/20] Train Loss: 0.6532 Train Accuracy: 0.7404 Val Loss: 0.6345 Val Accuracy: 0.7647 Val F1: 0.7110\n",
      "Epoch [6/20] Train Loss: 0.5880 Train Accuracy: 0.7719 Val Loss: 0.6211 Val Accuracy: 0.7703 Val F1: 0.7162\n",
      "Epoch [7/20] Train Loss: 0.5449 Train Accuracy: 0.7900 Val Loss: 0.6291 Val Accuracy: 0.7687 Val F1: 0.7260\n",
      "Epoch [8/20] Train Loss: 0.5045 Train Accuracy: 0.8048 Val Loss: 0.6426 Val Accuracy: 0.7630 Val F1: 0.7366\n",
      "Epoch [9/20] Train Loss: 0.4676 Train Accuracy: 0.8196 Val Loss: 0.6737 Val Accuracy: 0.7610 Val F1: 0.7380\n",
      "Epoch [10/20] Train Loss: 0.4297 Train Accuracy: 0.8362 Val Loss: 0.6895 Val Accuracy: 0.7533 Val F1: 0.7482\n",
      "Epoch [11/20] Train Loss: 0.3970 Train Accuracy: 0.8560 Val Loss: 0.7134 Val Accuracy: 0.7463 Val F1: 0.7465\n",
      "Epoch [12/20] Train Loss: 0.3774 Train Accuracy: 0.8662 Val Loss: 0.7379 Val Accuracy: 0.7497 Val F1: 0.7481\n",
      "Epoch [13/20] Train Loss: 0.3436 Train Accuracy: 0.8837 Val Loss: 0.7527 Val Accuracy: 0.7487 Val F1: 0.7478\n",
      "Epoch [14/20] Train Loss: 0.3183 Train Accuracy: 0.8945 Val Loss: 0.8081 Val Accuracy: 0.7377 Val F1: 0.7406\n",
      "Epoch [15/20] Train Loss: 0.3006 Train Accuracy: 0.9039 Val Loss: 0.8184 Val Accuracy: 0.7473 Val F1: 0.7455\n",
      "Epoch [16/20] Train Loss: 0.2835 Train Accuracy: 0.9096 Val Loss: 0.8614 Val Accuracy: 0.7373 Val F1: 0.7396\n",
      "Epoch [17/20] Train Loss: 0.2695 Train Accuracy: 0.9155 Val Loss: 0.8715 Val Accuracy: 0.7383 Val F1: 0.7398\n",
      "Epoch [18/20] Train Loss: 0.2571 Train Accuracy: 0.9213 Val Loss: 0.9076 Val Accuracy: 0.7460 Val F1: 0.7450\n",
      "Epoch [19/20] Train Loss: 0.2454 Train Accuracy: 0.9253 Val Loss: 0.9463 Val Accuracy: 0.7447 Val F1: 0.7434\n",
      "Epoch [20/20] Train Loss: 0.2356 Train Accuracy: 0.9299 Val Loss: 0.9865 Val Accuracy: 0.7350 Val F1: 0.7287\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(vocab_size, embedding_dim, hidden_size, output_size, max_length).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Train Loss: 0.2226 Train Accuracy: 0.9316 Val Loss: 0.9977 Val Accuracy: 0.7493 Val F1: 0.7437\n",
      "Epoch [2/10] Train Loss: 0.2105 Train Accuracy: 0.9393 Val Loss: 1.0501 Val Accuracy: 0.7417 Val F1: 0.7377\n",
      "Epoch [3/10] Train Loss: 0.2092 Train Accuracy: 0.9373 Val Loss: 1.0703 Val Accuracy: 0.7340 Val F1: 0.7277\n",
      "Epoch [4/10] Train Loss: 0.2036 Train Accuracy: 0.9380 Val Loss: 1.0961 Val Accuracy: 0.7497 Val F1: 0.7400\n",
      "Epoch [5/10] Train Loss: 0.1925 Train Accuracy: 0.9415 Val Loss: 1.0931 Val Accuracy: 0.7470 Val F1: 0.7411\n",
      "Epoch [6/10] Train Loss: 0.1924 Train Accuracy: 0.9399 Val Loss: 1.0990 Val Accuracy: 0.7477 Val F1: 0.7404\n",
      "Epoch [7/10] Train Loss: 0.1835 Train Accuracy: 0.9451 Val Loss: 1.1352 Val Accuracy: 0.7193 Val F1: 0.7182\n",
      "Epoch [8/10] Train Loss: 0.1891 Train Accuracy: 0.9413 Val Loss: 1.1440 Val Accuracy: 0.7420 Val F1: 0.7358\n",
      "Epoch [9/10] Train Loss: 0.1713 Train Accuracy: 0.9488 Val Loss: 1.1390 Val Accuracy: 0.7463 Val F1: 0.7401\n",
      "Epoch [10/10] Train Loss: 0.1693 Train Accuracy: 0.9483 Val Loss: 1.2060 Val Accuracy: 0.7467 Val F1: 0.7420\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Hàm lưu mô hình\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Mô hình đã được lưu tại {path}\")\n",
    "\n",
    "# Hàm tải mô hình\n",
    "def load_model(model, path, device):\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    print(f\"Mô hình đã được nạp từ {path}\")\n",
    "\n",
    "# Hàm tiền xử lý và mã hóa câu đầu vào\n",
    "def preprocess_input(sentence, tokenizer, max_length=128):\n",
    "    sentence = remove_emoji(sentence)  # Loại bỏ emoji\n",
    "    sentence = clean_text(sentence)   # Làm sạch văn bản\n",
    "    tokens = tokenizer(sentence, truncation=True, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "    return tokens['input_ids']\n",
    "\n",
    "# Hàm kiểm tra mô hình với một câu đầu vào\n",
    "def test_model(model, tokenizer, sentence, device):\n",
    "    model.eval()\n",
    "    input_ids = preprocess_input(sentence, tokenizer).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        _, predicted_label = torch.max(outputs, 1)\n",
    "    \n",
    "    label_map = {0: \"Tích cực (POS)\", 1: \"Trung tính (NEU)\", 2: \"Tiêu cực (NEG)\"}\n",
    "    return label_map[predicted_label.item()]\n",
    "\n",
    "# Cập nhật hàm train để lưu mô hình tốt nhất và cuối cùng\n",
    "best_model_path = \"./model/best_lstm_model.pth\"\n",
    "\n",
    "train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=10,  best_model_path=best_model_path)\n",
    "\n",
    "# Nạp lại mô hình tốt nhất\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình đã được nạp từ ./model/best_lstm_model.pth\n",
      "\n",
      "Kết quả thử nghiệm:\n",
      "Câu: \"Tối nay có bạn nào đi nhậu cho vui ko nào. Mình năm nhất nam nek, bn nào đi lên kèo nào \" --> Dự đoán: Trung tính (NEU)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18780\\3502001185.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "load_model(model, best_model_path, device)\n",
    "\n",
    "# Ví dụ kiểm tra với các câu đầu vào\n",
    "test_sentences = [\n",
    "    '''Tối nay có bạn nào đi nhậu cho vui ko nào. Mình năm nhất nam nek, bn nào đi lên kèo nào '''\n",
    "]\n",
    "\n",
    "print(\"\\nKết quả thử nghiệm:\")\n",
    "for sentence in test_sentences:\n",
    "    prediction = test_model(model, tokenizer, sentence, device)\n",
    "    print(f\"Câu: \\\"{sentence}\\\" --> Dự đoán: {prediction}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
